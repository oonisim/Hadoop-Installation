#--------------------------------------------------------------------------------
# SPARK_ADMIN account MUST be in HADOOP_GROUP and be able to read HADOOP_CONF_DIR.
# https://stackoverflow.com/a/36776378
# https://stackoverflow.com/a/40905888/4281353
# https://stackoverflow.com/a/40906741/4281353
#--------------------------------------------------------------------------------
- name: "Set {{ HADOOP_HOME }} permission"
  file:
    path: "{{ HADOOP_HOME }}"
    group: "{{ HADOOP_GROUP }}"
    mode: "u=rwX,g=rX"
    recurse: yes

- name: "Grant HDFS write access to /user"
  become: true
  become_user: "{{ HADOOP_ADMIN }}"
  shell: | 
    hadoop fs -mkdir -p /user
    hadoop fs -chown -R {{ HADOOP_ADMIN }}:{{ HADOOP_GROUP }} /user
    hadoop fs -chmod -R ug+rwx /user
  environment: 
    PATH: "{{ ansible_env.PATH }}:{{ HADOOP_HOME }}/bin:{{ SPARK_HOME }}:/bin"
    JAVA_HOME: "{{ java_home.stdout }}"
    HADOOP_HOME: "{{ HADOOP_HOME }}"

#--------------------------------------------------------------------------------
# See spark-defaults.conf for parameters.
# - spark.eventLog.enabled
# - spark.eventLog.dir
#--------------------------------------------------------------------------------
- name: "Create event log directory in HDFS"
  become: true
  become_user: "{{ HADOOP_ADMIN }}"
  # The first line is a header    
  shell: |
    hadoop fs -mkdir -p {{ SPARK_LOG_DIR }}
    hadoop fs -chown -R {{ SPARK_ADMIN }}:{{ HADOOP_GROUP }} {{ SPARK_LOG_DIR }}
    hadoop fs -chmod -R ugo+rwx {{ SPARK_LOG_DIR }}
  environment: 
    PATH: "{{ ansible_env.PATH }}:{{ HADOOP_HOME }}/bin:{{ SPARK_HOME }}:/bin"
    JAVA_HOME: "{{ java_home.stdout }}"
    HADOOP_HOME: "{{ HADOOP_HOME }}"
